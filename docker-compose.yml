# Docker Compose configuration - version field is optional in modern compose


services:
  # ==================== PostgreSQL Database ====================
  postgres:
    image: postgres:16-alpine
    container_name: trading-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - ./init-db.sql:/docker-entrypoint-initdb.d/01-init.sql
      - postgres_data:/var/lib/postgresql/data
    networks:
      - trading-network
    mem_limit: 1.5g
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s


  # ==================== Database Migration ====================
  migrate:
    image: postgres:16-alpine
    container_name: trading-migrate
    environment:
      - PGPASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - ./services/database/cascade-migration.sql:/docker-entrypoint-initdb.d/cascade-migration.sql
    command: >
      sh -c "
        psql -h postgres -U ${POSTGRES_USER} -d ${POSTGRES_DB} -f /docker-entrypoint-initdb.d/cascade-migration.sql
      "
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - trading-network

  # ==================== Redis Cache ====================
  redis:
    image: redis:7-alpine
    container_name: trading-redis
    restart: unless-stopped
    command: redis-server --requirepass ${REDIS_PASSWORD} --maxmemory 256mb --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - trading-network
    mem_limit: 256m

  # ==================== RabbitMQ Message Queue ====================
  rabbitmq:
    image: rabbitmq:3.13-management-alpine
    container_name: trading-rabbitmq
    restart: unless-stopped
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_DEFAULT_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_DEFAULT_PASS}
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    networks:
      - trading-network
    mem_limit: 256m

  # ==================== n8n Orchestrator ====================
  n8n:
    image: n8nio/n8n:latest
    container_name: trading-n8n
    restart: unless-stopped
    ports:
      - "5678:5678"
    environment:
      - N8N_BASIC_AUTH_ACTIVE=${N8N_BASIC_AUTH_ACTIVE}
      - N8N_BASIC_AUTH_USER=${N8N_BASIC_AUTH_USER}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_BASIC_AUTH_PASSWORD}
      - N8N_HOST=${N8N_HOST}
      - N8N_PORT=${N8N_PORT}
      - N8N_PROTOCOL=http
      - WEBHOOK_URL=http://localhost:5678/
      - GENERIC_TIMEZONE=${TIMEZONE}
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_DATABASE=${POSTGRES_DB}
      - DB_POSTGRESDB_USER=${POSTGRES_USER}
      - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD}
      - N8N_RUNNERS_ENABLED=true
      - N8N_BLOCK_ENV_ACCESS_IN_NODE=false
      - N8N_GIT_NODE_DISABLE_BARE_REPOS=true
    volumes:
      - n8n_data:/home/node/.n8n
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - trading-network
    mem_limit: 512m

  # ==================== Video Processor ====================
  video-processor:
    build:
      context: ./services/video-processor
      dockerfile: Dockerfile
    container_name: trading-video-processor
    restart: unless-stopped
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - RABBITMQ_URL=amqp://${RABBITMQ_DEFAULT_USER}:${RABBITMQ_DEFAULT_PASS}@rabbitmq:5672/
      - DELETE_VIDEO_AFTER_PROCESSING=${DELETE_VIDEO_AFTER_PROCESSING}
      - MEMORY_CLEANUP_INTERVAL=${MEMORY_CLEANUP_INTERVAL}
      - USE_CASCADE=${USE_CASCADE}
      - CONFIDENCE_THRESHOLD=${CONFIDENCE_THRESHOLD}
      - WHISPER_MODEL=${WHISPER_MODEL}
      - WHISPER_CASCADE=${WHISPER_CASCADE}
    volumes:
      - ./data/videos:/data/videos
      - ./data/processed:/data/processed
      - ./data/models:/app/models
      - ./data/logs:/app/logs
    depends_on:
      - postgres
      - redis
      - rabbitmq
    networks:
      - trading-network
    mem_limit: 2.5g
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    healthcheck:
      test: ["CMD-SHELL", "pgrep -f worker.py || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==================== Backtesting Service ====================
  backtesting-service:
    build:
      context: ./services/backtesting-service
      dockerfile: Dockerfile
    container_name: trading-backtesting
    restart: unless-stopped
    ports:
      - "8001:8001"
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - MIN_WIN_RATE_TO_SAVE=${MIN_WIN_RATE_TO_SAVE}
      - MIN_PROFIT_FACTOR=${MIN_PROFIT_FACTOR}
    depends_on:
      - postgres
      - migrate
    networks:
      - trading-network
    mem_limit: 1g
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==================== Ollama LLM ====================
  ollama:
    image: ollama/ollama:latest
    container_name: trading-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    environment:
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - trading-network
    mem_limit: 4.5g
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # ==================== Memory Cleaner ====================
  memory-cleaner:
    build:
      context: ./services/memory-cleaner
      dockerfile: Dockerfile
    container_name: trading-memory-cleaner
    restart: unless-stopped
    environment:
      - CLEANUP_INTERVAL=600
      - MEMORY_THRESHOLD_MB=1500
    volumes:
      - ./data/logs:/app/logs
    depends_on:
      - video-processor
    networks:
      - trading-network
    mem_limit: 64m

networks:
  trading-network:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  rabbitmq_data:
    driver: local
  n8n_data:
    driver: local
  ollama_data:
    driver: local